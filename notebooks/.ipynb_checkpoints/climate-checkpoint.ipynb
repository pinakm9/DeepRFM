{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7059933-fba0-4a07-a12a-d8fecc5cc5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on L63 ...\n",
      "Time taken by sinkhorn_div is 0.0981 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'L63'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m w \u001b[38;5;241m=\u001b[39m w2\u001b[38;5;241m.\u001b[39msinkhorn_div(reconstructed_attractor[random_index1], attractor[random_index0])\n\u001b[1;32m     47\u001b[0m results \u001b[38;5;241m=\u001b[39m [[dynamical_system, architecture, w]]\n\u001b[0;32m---> 48\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/pandas/core/frame.py:817\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    808\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    809\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m         dtype,\n\u001b[1;32m    816\u001b[0m     )\n\u001b[0;32m--> 817\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    825\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    826\u001b[0m         data,\n\u001b[1;32m    827\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    831\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    832\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/pandas/core/internals/construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/pandas/core/internals/construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[1;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[1;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/pandas/core/construction.py:605\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    601\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m subarr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;66;03m# we will try to copy by-definition here\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/pandas/core/construction.py:794\u001b[0m, in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    792\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_cast_to_integer_array(arr, dtype)\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 794\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(arr, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subarr\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'L63'"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "from pathlib import Path\n",
    "from os.path import dirname, realpath\n",
    "script_dir = Path(dirname(realpath('.')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "import numpy as np\n",
    "import utility as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob, json\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import oneshot as sm\n",
    "import rfm, skipRFM, localRFM, localSkip, deepSkip, deepRFM, localDeepRFM, localDeepSkip, localDeepSkipN\n",
    "# import parallel_euler as arch1\n",
    "import torch, time\n",
    "from torch import nn\n",
    "import config\n",
    "import count_params as cp\n",
    "import wasserstein as w2\n",
    "\n",
    "\n",
    "L = 200\n",
    "config_ids = ['config_1_s', 'config_1_s', 'config_1']\n",
    "train_sizes = [int(5e4), int(1e5), int(1e5)]\n",
    "dynamical_systems = ['L63', 'L96', f'KS-{L}']\n",
    "\n",
    "data_folder = '../data'\n",
    "N_hat = 300\n",
    "\n",
    "columns = ['dynamical_system', 'architecture', 'w2']\n",
    "file_path = f'{data_folder}/w2.csv'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "for dynamical_system, config_id, train_size in zip(dynamical_systems, config_ids, train_sizes):\n",
    "    print(f\"Working on {dynamical_system} ...\")\n",
    "    folder = f'{data_folder}/{dynamical_system}/{config_id}/attractor'\n",
    "    attractor = torch.tensor(np.load(f'{folder}/train.npy')).T\n",
    "    random_index0 = torch.randperm(len(attractor))[:N_hat]\n",
    "    for architecture, setup, results in ut.get_best_models(dynamical_system, config_id, root=data_folder):\n",
    "        architecture = architecture.split(\"_\")[0]\n",
    "        reconstructed_attractor = torch.tensor(np.load(f'{folder}/{architecture}/attractor.npy')).T\n",
    "        random_index1 = torch.randperm(len(reconstructed_attractor))[:N_hat]\n",
    "        w = w2.sinkhorn_div(reconstructed_attractor[random_index1], attractor[random_index0])\n",
    "        results = [[dynamical_system, architecture, w]]\n",
    "        pd.DataFrame(results, columns=columns).to_csv(file_path, mode='a', index=False, header=not os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d6209a-4612-4b06-93ba-4d566598b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L63', 'RFM', tensor(2.0925)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec823cf6-c6e7-4bcb-b432-7d3344ce2163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
